{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14921627",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    hmm_file = '# hmm file path'\n",
    "    feat_scp = '# feature list file path'\n",
    "    lexicon_file = '# lexicon file path'\n",
    "    phones_file = '# phone list file path'\n",
    "    insert_sil = True # whether to insert silenece at the beginning and the end\n",
    "    \n",
    "    # open phones_file and make up a list of phones\n",
    "    phone_list = []\n",
    "    with open(phones_file, mode = 'r') as f:\n",
    "        for line in f:\n",
    "            phone = line.split()[0]\n",
    "            phone_list.append(phone)\n",
    "            \n",
    "    # open lexicon_file and make up a lexicon list with word, phones that comprise the word, the matching index of the phone sequence\n",
    "    lexicon = []\n",
    "    with open(lexicon_file, mode = 'r') as f:\n",
    "        for line in f:\n",
    "            word = line.split()[0]\n",
    "            phones = line.split()[1:]\n",
    "            if insert_sil:\n",
    "                phones.insert(0, phone_list[0])\n",
    "                phones.append(phone_list[0])\n",
    "            # create the matching index sequences\n",
    "            ph_int = []\n",
    "            for ph in phones:\n",
    "                if ph in phone_list:\n",
    "                    ph_int.append(phone_list.index(ph))\n",
    "                else:\n",
    "                    sys.stderr.write('invalud phone %s' % (ph))\n",
    "            lexicon.append({'word': word, \n",
    "                           'phones': phones, \n",
    "                           'ph_int': ph_int})\n",
    "    \n",
    "    # read HMM file \n",
    "    hmm = MonoPhoneHMM()\n",
    "    hmm = hmm.load(hmm_file)\n",
    "    \n",
    "    # read feature file \n",
    "    with open(feat_scp, mode = 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            utt_id, feat_path = parts[0], parts[1]\n",
    "            \n",
    "            feat = np.fromfile(feat_path, dtype = np.float32)\n",
    "            feat = feat.reshape(-1, hmm.num_dims)\n",
    "            \n",
    "            # execute word recognisation\n",
    "            (result, detail)  = hmm.recognize(feat, lexicon)\n",
    "            \n",
    "            sys.stdout.write('%s %s\\n' % (utt, ff))\n",
    "            sys.stdout.write('Result = %s\\n' % (result))\n",
    "            sys.stdout.write('Ranking]\\n')\n",
    "            for res in detail:\n",
    "                sys.stdout.write(' %s %f\\n' % (res['word'], res['score']))\n",
    "        \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
